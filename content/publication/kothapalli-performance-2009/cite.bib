@inproceedings{kothapalli_performance_2009,
 abstract = {The significant growth in computational power of modern Graphics Processing Units (GPUs) coupled with the advent of general purpose programming environments like NVIDIA's CUDA, has seen GPUs emerging as a very popular parallel computing platform. Till recently, there has not been a performance model for GPGPUs. The absence of such a model makes it difficult to definitively assess the suitability of the GPU for solving a particular problem and is a significant impediment to the mainstream adoption of GPUs as a massively parallel (super)computing platform. In this paper we present a performance prediction model for the CUDA GPGPU platform. This model encompasses the various facets of the GPU architecture like scheduling, memory hierarchy, and pipelining among others. We also perform experiments that demonstrate the effects of various memory access strategies. The proposed model can be used to analyze pseudo code for a CUDA kernel to obtain a performance estimate, in a way that is similar to performing asymptotic analysis. We illustrate the usage of our model and its accuracy with three case studies: matrix multiplication, list ranking, and histogram generation.},
 author = {Kothapalli, K. and Mukherjee, R. and Rehman, M. S. and Patidar, S. and Narayanan, P. J. and Srinathan, K.},
 booktitle = {2009 International Conference on High Performance Computing (HiPC)},
 copyright = {All rights reserved},
 doi = {10.1109/HIPC.2009.5433179},
 file = {Full Text:files/120/Kothapalli et al. - 2009 - A performance prediction model for the CUDA GPGPU .pdf:application/pdf;Snapshot:files/121/5433179.html:text/html;IEEE Xplore Abstract Record:files/134/5433179.html:text/html},
 keywords = {asymptotic analysis, computational power, Concurrent computing, coprocessors, CUDA GPGPU platform, CUDA kernel, general purpose programming environments, GPU architecture, Graphics, graphics processing units, histogram generation, Impedance, Kernel, list ranking, matrix multiplication, memory access strategy, memory architecture, Memory architecture, memory hierarchy, NVIDIA, parallel architectures, parallel computing platform, Parallel processing, parallel supercomputing platform, Performance analysis, performance prediction model, pipeline processing, Pipeline processing, pipelining, Predictive models, processor scheduling, programming environments, Programming environments, scheduling},
 month = {December},
 note = {ISSN: 1094-7256},
 pages = {463--472},
 title = {A performance prediction model for the CUDA GPGPU platform},
 year = {2009}
}

