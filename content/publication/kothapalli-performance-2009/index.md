---
# Documentation: https://wowchemy.com/docs/managing-content/

title: A performance prediction model for the CUDA GPGPU platform
subtitle: ''
summary: ''
authors:
- K. Kothapalli
- R. Mukherjee
- M. S. Rehman
- S. Patidar
- P. J. Narayanan
- K. Srinathan
tags:
- '"asymptotic analysis"'
- '"computational power"'
- '"Concurrent computing"'
- '"coprocessors"'
- '"CUDA GPGPU platform"'
- '"CUDA kernel"'
- '"general purpose programming environments"'
- '"GPU architecture"'
- '"Graphics"'
- '"graphics processing units"'
- '"histogram generation"'
- '"Impedance"'
- '"Kernel"'
- '"list ranking"'
- '"matrix multiplication"'
- '"memory access strategy"'
- '"memory architecture"'
- '"Memory architecture"'
- '"memory hierarchy"'
- '"NVIDIA"'
- '"parallel architectures"'
- '"parallel computing platform"'
- '"Parallel processing"'
- '"parallel supercomputing platform"'
- '"Performance analysis"'
- '"performance prediction model"'
- '"pipeline processing"'
- '"Pipeline processing"'
- '"pipelining"'
- '"Predictive models"'
- '"processor scheduling"'
- '"programming environments"'
- '"Programming environments"'
- '"scheduling"'
categories: []
date: '2009-12-01'
lastmod: 2021-03-04T01:25:40-06:00
featured: false
draft: false

# Featured image
# To use, add an image named `featured.jpg/png` to your page's folder.
# Focal points: Smart, Center, TopLeft, Top, TopRight, Left, Right, BottomLeft, Bottom, BottomRight.
image:
  caption: ''
  focal_point: ''
  preview_only: false

# Projects (optional).
#   Associate this post with one or more of your projects.
#   Simply enter your project's folder or file name without extension.
#   E.g. `projects = ["internal-project"]` references `content/project/deep-learning/index.md`.
#   Otherwise, set `projects = []`.
projects: []
publishDate: '2021-03-04T07:25:40.021443Z'
publication_types:
- '1'
abstract: "The significant growth in computational power of modern Graphics Processing\
  \ Units (GPUs) coupled with the advent of general purpose programming environments\
  \ like NVIDIA's CUDA, has seen GPUs emerging as a very popular parallel computing\
  \ platform. Till recently, there has not been a performance model for GPGPUs. The\
  \ absence of such a model makes it difficult to definitively assess the suitability\
  \ of the GPU for solving a particular problem and is a significant impediment to\
  \ the mainstream adoption of GPUs as a massively parallel (super)computing platform.\
  \ In this paper we present a performance prediction model for the CUDA GPGPU platform.\
  \ This model encompasses the various facets of the GPU architecture like scheduling,\
  \ memory hierarchy, and pipelining among others. We also perform experiments that\
  \ demonstrate the effects of various memory access strategies. The proposed model\
  \ can be used to analyze pseudo code for a CUDA kernel to obtain a performance estimate,\
  \ in a way that is similar to performing asymptotic analysis. We illustrate the\
  \ usage of our model and its accuracy with three case studies: matrix multiplication,\
  \ list ranking, and histogram generation."
publication: '*2009 International Conference on High Performance Computing (HiPC)*'
doi: 10.1109/HIPC.2009.5433179
---
